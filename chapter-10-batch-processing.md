# 10장 Batch

## 요약
시스템은 세 가지로 나눌 수 있다. 
 
(1) 서비스(오프라인 시스템)  
사용자의 요청을 기다린다. 요청이 왔을 때, 응답이 빠를수록 좋다. 응답시간이 주요한 성능 지표다. 

(2) 배치(오프라인 시스템)
대용량 데이터를 input으로 받고 job을 실행한 후 결과물을 만들어낸다.
온라인 시스템과 달리, 요청을 기다리는 사용자가 없다. 처리를 기다리는 개발자가 있다. 성능 테스트의 주요 지표는 throughput이다.
주 사용자는 사내 직원이다. 

(3) 스트림(준실시간 시스템)
Stream processing system이라고도 한다. 오프라인 시스템과 같이, 준실시간 시스템도 input을 받고 결과물을 만든다.
차이점은, 준실시간 시스템은 fixed inputd을 받는게 아니라, 연속적인 이벤트들을 input으로 받는다는 것이다.
이러한 차이 때문에, 준실시간 시스템에서는 latency가 중요하다.

이 장에서는 배치 시스템에 대해 설명한다.

### 유닉스의 배치 처리 과정
유닉스 쉘 스크립트로 배치 프로그램을 만들 수 있다.
```shell script
cat example.log  |
awk '{print $7}' |
sort             |
uniq             |
```
위 명령어는 (1) example.log를 읽은 후, (2) 각 줄을 공백으로 파싱하여 7번째 필드를 가져온 뒤, (3) 정렬하여, (4) 중복되는 줄을 제거한다.
각 명령어는 파이프라인으로 결과물을 다음 명령어로 전송한다.
input을 받아서 output을 만드는 일반적인 배치 특징을 볼 수 있다.

한편 unix의 배치 파이프라인은 한개의 컴퓨터 환경에서밖에 쓰일 수 밖에 없다. 분산 환경에서 배치 처리가 가능한 framework이 필요하다.
Hadoop이 등장했다. Hadoop은 여러 컴퓨터(분산 환경)에서의 배치 처리를 지원한다. 

### MapReducer
MapReduce는 분산환경에서 배치 프로그램을 효과적으로 돌릴 수 있게 만든 알고리즘이다. Hadoop은 MapReducer를 구현하여, HDFS라는 파일 시스템을 만들었다.

MapReducer 알고리즘은 다음과 같다.  

mapper: 
sorting 과정 전단계다. sorting 과정에 들어갈 데이터를 준비한다.  
위 unix 예시의 `awk '{print $7}'`에 대응된다. 
 
reducer:
sorting 과정 후단계다. sorting 과정 이후의 데이터를 처리한다.  
위 unix 예시의 `uniq -c`에 대응된다.

MapReduce는 broadcast hash join, partitioned hash join과 같은 여러가지 join 알고리즘을 사용한다.

## 느낀점
업무에서 배치를 많이 쓴다.
팀에서 배치의 의미는 임의의 시간에 시작하여, 수행이 끝나면 실행을 멈추는 프로그램이다.
예로 들어, 특정 데이터를 만드는 작업, 또는 특정 데이터를 변경하는 작업을 배치로 처리하고 있다.  

대용량의 데이터를 처리하는 작업도 있다.
airflow에 spark.sql을 등록함으로써 대용량의 데이터를 처리한다.
airflow에서의 spark.sql을 실행하는 job은, 책에 있는 배치의 특징을 잘 보여준다.
(1) 대용량의 데이터를 처리하며 (2) input과 output이 구분되며(input을 변경하지 않음) (3) 특정 시간에 시작하여 수행이 끝나면 job이 끝난다.
회사에서는 위 작업을 배치라고 하지는 않지만, 책 기준이라면 배치라고 볼 수 있다.

책 기준이라면 배치가 아니지만, 회사에서 배치라고 부르는 프로그램들이 많다.
예로 들어, 대용량 데이터 처리를 하지 않는 배치 프로그램들이 있다.
아주 적은 데이터를 업데이트 하기 위해 spring batch를 활용하여 임의의 시간에 배치를 수행한다.(운영성 이슈 해결)
또한, input 자체를 수정하는 배치도 업무에서 매우 흔하다.(RDS에서 데이터 수정)


